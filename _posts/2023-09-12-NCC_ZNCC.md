---
layout: post
title: "NCC & ZNCC"
date:   2023-09-12
tags: [default]
comments: true
author: 2c984r83y
---
## Stereo matching and depth compute

### Step

1. 采集图像
2. 极线矫正
3. 特征匹配
4. 深度恢复

NCC与ZNCC是衡量特征匹配的算法，一般采用WTA的方法得到视察值d

## NCC

### 互相关系数

相关系数：

$ r(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)} } $

Where:

$ X $ is left image.

$ Y $ is right imag.

$ Cov(X,Y) $ 是左右两图的协方差

$ Var(X) $ 是左图自己的方差

### 归一化互相关

#### 简介

归一化相关性（normalization cross-correlation, NCC）使用类似于卷积核的n*n的匹配窗口对左右图像进行处理 ，检测左右匹配窗口的相似度，NCC为左右图方框对应的NCC平均值。

**边缘情况如何处理?**
[ scipy.ndimage.uniform_filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.uniform_filter.html)函数是一个多维均匀滤波器，滤波器窗口大小为 `size`参数指定，默认为3.
使用改函数进行匹配窗口的平均值计算，该函数的 `mode`参数可以设置边缘情况的处理方式。

`scipy.ndimage.uniform_filter(input, size=3, output=None, mode='reflect', cval=0.0, origin=0, *, axes=None)`
> The mode parameter determines how the input array is extended when the filter overlaps a border. By passing a sequence of modes with length equal to the number of dimensions of the input array, different modes can be specified along each axis. Default value is ‘reflect’. The valid values and their behavior is as follows:
>
> * ‘reflect’ (d c b a |**a b c d** | d c b a)
>   The input is extended by reflecting about the edge of the last pixel. This mode is also sometimes referred to as half-sample symmetric.
> * ‘constant’ (k k k k |**a b c d**| k k k k)
>   The input is extended by filling all values beyond the edge with the same constant value, defined by the cval parameter.
> * ‘nearest’ (a a a a | **a b c d**| d d d d)
>   The input is extended by replicating the last pixel.

双目匹配需要基线矫正，保证两幅图像只是在水平方向发生位移，产生视差。

**协方差：**

$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$

**方差：**

$Var(X)=E[(X-E(x))^{2}]$

**NCC Formular:**

$NCC(p,d)=\frac{\sum_{(x,y)\in W_p}^{}(I_1(x,y)-\overline{I_1}(p_x,p_y)\cdot (I_2(x,y)-\overline{I_2}(p_x+d,p_y) ) }{\sqrt{\sum_{(x,y)\in W_p}^{}(I_1(x,y)-\overline{I_1}(p_x,p_y))^{2} \cdot \sum_{(x,y)\in W_p}^{}(I_2(x,y)-\overline{I_2}(p_x+d,p_y))^{2}} }$

Where:

$NCC \in [-1,1]$,若$NCC=-1$，表示完全不相关；若 $NCC=1$，表示完全匹配

* $I_1$是左图，$I_2$是右图;
* $W_p$是以待匹配像素坐标为中心的匹配窗口；
* $I_1(x,y)$是左图中待匹配像素值，坐标$(p_x,p_y)$；
* $I_2(x+d,y)$是右图对应位置x坐标偏移d像素后的像素值，红框表示；
* $\overline{I}_1(p_x,p_y)$是左图匹配窗口所有像素均值；
* $\overline{I}_2(p_x+d,p_y)$是右图匹配所有窗口像素均值；

![1694528045454](https://github.com/2c984r83y/2c984r83y.github.io/blob/main/_posts/image/2023-09-12-ZNCC/1694528045454.png?raw=true "NCC计算示意图")

## ZNCC

### 简介

ZNCC(Zero-normalized cross-correlation)

## Implementation

### NCC

#### Python scripts

```python

from PIL import Image
from pylab import *
import cv2
from numpy import *
from numpy.ma import array
from scipy.ndimage import filters
import scipy.misc
import imageio
 
 
def plane_sweep_ncc(im_l, im_r, start, steps, wid):
    """ 使用归一化的互相关计算视差图像 """
    m, n = im_l.shape
    # 创建保存不同求和值的数组
    mean_l = zeros((m, n))
    mean_r = zeros((m, n))
    s = zeros((m, n))
    s_l = zeros((m, n))
    s_r = zeros((m, n))
    # 创建保存深度平面的数组
    dmaps = zeros((m, n, steps))
    # 计算图像块的平均值
    filters.uniform_filter(im_l, wid, mean_l)
    filters.uniform_filter(im_r, wid, mean_r)
    # 归一化图像
    norm_l = im_l - mean_l
    norm_r = im_r - mean_r
    # 尝试不同的视差
    #  steps 是视差的最大可能值
    for displ in range(steps):
        # 将左边图像移动到右边，计算加和
        # np.roll() 函数将数组元素向后移动 -displ - start 个单位
        # 和归一化, s 为 ncc 的分子
        filters.uniform_filter(np.roll(norm_l, -displ - start) * norm_r, wid, s)  
        
        filters.uniform_filter(np.roll(norm_l, -displ - start) * np.roll(norm_l, -displ - start), wid, s_l)
        filters.uniform_filter(norm_r * norm_r, wid, s_r)  # 和反归一化
        # 保存 ncc 的值在 dmaps 中
        dmaps[:, :, displ] = s / sqrt(s_l * s_r)
        # 为每个像素选取最佳深度
        # 选取最大的的 dmaps ，即视差，WTA
    return np.argmax(dmaps, axis=2)

im_l = array(Image.open(r'D:/Dataset/teddy/im4.ppm').convert('L'), 'f')
im_r = array(Image.open(r'D:/Dataset/teddy/im5.ppm').convert('L'), 'f')

# 开始偏移，并设置步长
steps = 12
start = 4

# ncc 的宽度
wid = 12
 
res = plane_sweep_ncc(im_l, im_r, start, steps, wid)
# scipy.misc.imsave('depth.png', res)
# imageio.imsave('D:/Dataset/teddy/depth1.png', res)
imshow(res)
show()
```

## Reference

[Cross-correlation_Wikipedia](https://en.wikipedia.org/wiki/Cross-correlation)
