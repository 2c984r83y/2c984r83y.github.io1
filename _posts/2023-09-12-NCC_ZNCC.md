---
layout: post
title: "NCC & ZNCC"
date:   2023-09-12
tags: [default]
comments: true
author: 2c984r83y
---
## Stereo matching and depth compute

### Step

1. 采集图像
2. 极线矫正
3. 特征匹配
4. 深度恢复

NCC与ZNCC是衡量特征匹配的算法，一般采用WTA的方法得到视差，双目视觉的几何原理并不是本文的重点，挖个坑以后再填

## [标准差、方差、协方差、相关系数](https://zhuanlan.zhihu.com/p/266161140)

### 标准差

  $\sigma = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(X_i-\overline{X})^{2}}$

标准差越小，说明数据越集中

标准差描述了变量在整体变化过程中偏离均值的幅度

所以在协方差中标准差作为分母对协方差进行了归一化

### 方差

$Var(X)=\frac{1}{n}\sum_{i=1}^{n}(X_i-\overline{X})^{2}$

标准差的平方，衡量离散程度，计算每一个变量（观察值）与总体均数之间的差异

### 协方差

$Cov(X,Y)=E[(X-\overline{X})(Y-\overline{Y})]=E[XY]-E(X)E(Y)=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\overline{X})(Y_i-\overline{Y})$

协方差反映两个随机变量相关程度，若两变量变化趋势相同，协方差为正值，反之为负

### 相关系数

相关系数，亦称作皮尔逊相关系数  

相关系数是协方差的[归一化](https://blog.csdn.net/LiuXF93/article/details/88956643)(normalization)， 消除了两个变量量纲/变化幅度不同的影响。单纯反映两个变量在每单位变化的相似程度

$p=\frac{Cov(X,Y)}{\sigma_{x}\sigma_{y}}$

or

$r(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)} }$


Where:

$X$ is left image.

$Y$ is right imag.

$Cov(X,Y)$ 是左右两图的协方差

$Var(X)$ 是左图自己的方差

## NCC

### 简介

归一化相关性（normalization cross-correlation, NCC）使用类似于卷积核的n*n的匹配窗口对左右图像进行处理 ，检测左右匹配窗口的相似度，NCC为左右图方框对应的NCC平均值。

双目匹配需要基线矫正，保证两幅图像只是在水平方向发生位移，产生视差。

### **Formular**

$NCC(p,d)=\frac{\sum_{(x,y)\in W_p}^{}I_1(x,y)\cdot I_2(x+d,y) }{\sqrt{\sum_{(x,y)\in W_p}^{}I_1(x,y)^{2} \cdot \sum_{(x,y)\in W_p}^{}I_2(x,y)^{2}} }$

Where:

$NCC \in [-1,1]$,若$NCC=-1$，表示完全不相关；若 $NCC=1$，表示完全匹配

* $I_1$是左图，$I_2$是右图;
* $W_p$是以待匹配像素坐标为中心的匹配窗口；
* $I_1(x,y)$是左图中待匹配像素值，坐标$(p_x,p_y)$；
* $I_2(x+d,y)$是右图对应位置x坐标偏移d像素后的像素值，红框表示；

![1694528045454](https://github.com/2c984r83y/2c984r83y.github.io/blob/main/_posts/image/2023-09-12-ZNCC/1694528045454.png?raw=true "NCC计算示意图")

## ZNCC

### 简介

ZNCC(Zero-normalized cross-correlation),相较NCC更鲁棒，因为ZNCC公式里减去了窗口内的均值，更能抵御光照的变化.[[3]](https://blog.csdn.net/fb_help/article/details/88543086)

> NCC的公式记成NCC的公式，导致了很多误解。其实NCC的公式应用的特别少，多数使用的是ZNCC的公式，只不过有些人将ZNCC与NCC的名称弄混淆，导致NCC这个名词的知名度很高，其实多数使用的公式却是ZNCC。[[3]](https://blog.csdn.net/fb_help/article/details/88543086)

### **Formular**

$ZNCC(p,d)=\frac{\sum_{(x,y)\in W_p}^{}(I_1(x,y)-\overline{I_1}(p_x,p_y)\cdot (I_2(x,y)-\overline{I_2}(p_x+d,p_y) ) }{\sqrt{\sum_{(x,y)\in W_p}^{}(I_1(x,y)-\overline{I_1}(p_x,p_y))^{2} \cdot \sum_{(x,y)\in W_p}^{}(I_2(x,y)-\overline{I_2}(p_x+d,p_y))^{2}} }$

* $I_1$是左图，$I_2$是右图;
* $W_p$是以待匹配像素坐标为中心的匹配窗口；
* $I_1(x,y)$是左图中待匹配像素值，坐标$(p_x,p_y)$；
* $I_2(x+d,y)$是右图对应位置x坐标偏移d像素后的像素值，红框表示；
* $\overline{I}_1(p_x,p_y)$是左图匹配窗口所有像素均值；
* $\overline{I}_2(p_x+d,p_y)$是右图匹配所有窗口像素均值；

## [NCC与ZNCC的关系与向量理解[4]](https://en.wikipedia.org/wiki/Cross-correlation#Zero-normalized_cross-correlation9)

### 更优雅的公式

#### NCC

NCC is similar to ZNCC with the only difference of not subtracting the local mean value of intensities

$\frac{1}{n}\sum_{x,y}^{}\frac{1}{\sigma_f\sigma_t}f(x,y)t(x,y)$

#### ZNCC

cross-correlation of a template $t(x,y)$ with a subimage $f(x,y)$

$\frac{1}{n}\sum_{x,y}^{}\frac{1}{\sigma_f\sigma_t}(f(x,y)-\mu_f)(t(x,y)-\mu_t)$

Where:

* $n$ is the number of pixels in $t(x,y)$ and $f(x,y)$
* $\sigma_f$ and $\sigma_t$ are the standard deviations of $f(x,y)$ and $t(x,y)$
* $\mu_f$ and $\mu_t$ are the average of $f(x,y)$ and $t(x,y)$

### 以向量的角度

在泛函分析中，ZNCC可以被看作是两个归一化向量的内积(dot product)

That is, if

$F(x,y)=f(x,y)-\mu_f$

and

$T(x,y)=t(x,y)-\mu_t$

then the ZNCC is the normalized dot product of the two vectors:

$\left \langle \frac{F}{\left \| F \right \| },\frac{T}{\left \| T \right \| } \right \rangle$

因此，如果$f$和$t$是实矩阵，那么ZNCC相当于$F$与$T$所对应的单位向量夹角的余弦值,两向量之间的交角为0即余弦值为1时即两向量方向相同，反之相反

It is also the 2-dimensional version of Pearson product-moment correlation coefficient.

where:

* $\left \| \cdot \right \|$  is the  $L^2$norm.
* $\left \langle \cdot,\cdot \right \rangle $ is the inner product.
* Cauchy-Schwarz implies that the ZNCC has a range of $[-1,1]$.

> $L^2$ norm is the Euclidean norm, and is defined as the sum of the squares of the vector elements.
>
> $\left \| F \right \|=\sqrt{\sum_{1}^{n}(f(x,y)-\mu_f)}$
>
> $\left \| F \right \| \left \| T \right \| =n\sigma_f\sigma _t$
>
> And cos is:
>
> $cos\theta=\frac{a \cdot b}{\left | a \right | \left | a \right | }$

## Implementation

### **边缘像素如何处理?**

为了简化计算，这里并没有对图像进行裁切边缘的操作
[ scipy.ndimage.uniform_filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.uniform_filter.html)函数是一个多维均匀滤波器，滤波器窗口大小为 `size`参数指定，默认为3.
使用改函数进行匹配窗口的平均值计算，该函数的 `mode`参数可以设置边缘情况的处理方式。

`scipy.ndimage.uniform_filter(input, size=3, output=None, mode='reflect', cval=0.0, origin=0, *, axes=None)`

> The mode parameter determines how the input array is extended when the filter overlaps a border. By passing a sequence of modes with length equal to the number of dimensions of the input array, different modes can be specified along each axis. Default value is ‘reflect’. The valid values and their behavior is as follows:
>
> * ‘reflect’ (d c b a |**a b c d** | d c b a)
>   The input is extended by reflecting about the edge of the last pixel. This mode is also sometimes referred to as half-sample symmetric.
> * ‘constant’ (k k k k |**a b c d**| k k k k)
>   The input is extended by filling all values beyond the edge with the same constant value, defined by the cval parameter.
> * ‘nearest’ (a a a a | **a b c d**| d d d d)
>   The input is extended by replicating the last pixel.

### NCC

```python
from PIL import Image
from pylab import *
import cv2
from numpy import *
from numpy.ma import array
from scipy.ndimage import filters
import scipy.misc
import imageio
 
 
def plane_sweep_ncc(im_l, im_r, start, steps, wid):
    """ 使用归一化的互相关计算视差图像 """
    m, n = im_l.shape
    # 创建保存不同求和值的数组
    mean_l = zeros((m, n))
    mean_r = zeros((m, n))
    s = zeros((m, n))
    s_l = zeros((m, n))
    s_r = zeros((m, n))
    # 创建保存深度平面的数组
    dmaps = zeros((m, n, steps))

    # # only for ZNCC
    # # 计算图像块的平均值
    # filters.uniform_filter(im_l, wid, mean_l)
    # filters.uniform_filter(im_r, wid, mean_r)
    # # 归一化图像
    # norm_l = im_l - mean_l
    # norm_r = im_r - mean_r


    # 尝试不同的视差
    #  steps 是视差的最大可能值
    for displ in range(steps):
        # 将左边图像移动到右边，计算加和
        # np.roll() 函数将数组元素向后移动 -displ - start 个单位
        # 和归一化, s 为 ncc 的分子
        filters.uniform_filter(np.roll(norm_l, -displ - start) * norm_r, wid, s)  
  
        filters.uniform_filter(np.roll(norm_l, -displ - start) * np.roll(norm_l, -displ - start), wid, s_l)
        filters.uniform_filter(norm_r * norm_r, wid, s_r)  # 和反归一化
        # 保存 ncc 的值在 dmaps 中
        dmaps[:, :, displ] = s / sqrt(s_l * s_r)
        # 为每个像素选取最佳深度
        # 选取最大的的 dmaps ，即视差，WTA
    return np.argmax(dmaps, axis=2)

im_l = array(Image.open(r'D:/Dataset/teddy/im4.ppm').convert('L'), 'f')
im_r = array(Image.open(r'D:/Dataset/teddy/im5.ppm').convert('L'), 'f')

# 开始偏移，并设置步长
steps = 12
start = 4

# ncc 的宽度
wid = 12
 
res = plane_sweep_ncc(im_l, im_r, start, steps, wid)
# scipy.misc.imsave('depth.png', res)
# imageio.imsave('D:/Dataset/teddy/depth1.png', res)
imshow(res)
show()

```

### ZNCC

```python

from PIL import Image
from pylab import *
import cv2
from numpy import *
from numpy.ma import array
from scipy.ndimage import filters
import scipy.misc
import imageio
 
 
def plane_sweep_ncc(im_l, im_r, start, steps, wid):
    """ 使用归一化的互相关计算视差图像 """
    m, n = im_l.shape
    # 创建保存不同求和值的数组
    mean_l = zeros((m, n))
    mean_r = zeros((m, n))
    s = zeros((m, n))
    s_l = zeros((m, n))
    s_r = zeros((m, n))
    # 创建保存深度平面的数组
    dmaps = zeros((m, n, steps))
    # 计算图像块的平均值
    filters.uniform_filter(im_l, wid, mean_l)
    filters.uniform_filter(im_r, wid, mean_r)
    # 归一化图像
    norm_l = im_l - mean_l
    norm_r = im_r - mean_r
    # 尝试不同的视差
    #  steps 是视差的最大可能值
    for displ in range(steps):
        # 将左边图像移动到右边，计算加和
        # np.roll() 函数将数组元素向后移动 -displ - start 个单位
        # 和归一化, s 为 ncc 的分子
        filters.uniform_filter(np.roll(norm_l, -displ - start) * norm_r, wid, s)  
  
        filters.uniform_filter(np.roll(norm_l, -displ - start) * np.roll(norm_l, -displ - start), wid, s_l)
        filters.uniform_filter(norm_r * norm_r, wid, s_r)  # 和反归一化
        # 保存 ncc 的值在 dmaps 中
        dmaps[:, :, displ] = s / sqrt(s_l * s_r)
        # 为每个像素选取最佳深度
        # 选取最大的的 dmaps ，即视差，WTA
    return np.argmax(dmaps, axis=2)

im_l = array(Image.open(r'D:/Dataset/teddy/im4.ppm').convert('L'), 'f')
im_r = array(Image.open(r'D:/Dataset/teddy/im5.ppm').convert('L'), 'f')

# 开始偏移，并设置步长
steps = 12
start = 4

# ncc 的宽度
wid = 12
 
res = plane_sweep_ncc(im_l, im_r, start, steps, wid)
# scipy.misc.imsave('depth.png', res)
# imageio.imsave('D:/Dataset/teddy/depth1.png', res)
imshow(res)
show()
```

## Reference

[[1]标准差、方差、协方差、相关系数](https://zhuanlan.zhihu.com/p/266161140)
[[2]协方差和相关性的意义](https://blog.csdn.net/LiuXF93/article/details/8895664)
[[3]NCC与ZNCC](https://blog.csdn.net/fb_help/article/details/88543086)
[[4]Cross-correlation_Wikipedia](https://en.wikipedia.org/wiki/Cross-correlation)
[[5]scipy.ndimage.uniform_filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.uniform_filter.html)
